{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac09b9ab",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 7: Model Selection, Regularization, and Cross-Validation\n",
    "\n",
    "In this lab, you will practice using `scikit-learn` to generate models of various complexity. You'll then use the holdout method and K-fold cross-validation to select the models that generalize best.\n",
    "\n",
    "**Due Date: Monday, November 25, 11:59 PM PT.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c583aad",
   "metadata": {},
   "source": [
    "### Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk with others about this assignment, we ask that you **write your solutions individually**. If you discuss the assignment with others, please **include their names** in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1de13",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8625059b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "#from IPython.display import display, Latex, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365efd81",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Introduction\n",
    "\n",
    "For this lab, we will use a dataset to predict the house prices in Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4842b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a142dda-e3e8-4a7c-8f62-9710a01d68bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO  LSTAT  \n",
       "0     15.3   4.98  \n",
       "1     17.8   9.14  \n",
       "2     17.8   4.03  \n",
       "3     18.7   2.94  \n",
       "4     18.7   5.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.DataFrame(data)\n",
    "boston.columns = [\"CRIM\", \"ZN\", \"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PTRATIO\",\"B\",\"LSTAT\"]\n",
    "boston_target = target\n",
    "boston.drop(\"B\", axis = 1,inplace = True)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50157e81-d979-49c0-a42f-140870665954",
   "metadata": {},
   "source": [
    "This dataset relates a number of features to the median house value of occupied homes. \n",
    "\n",
    " - CRIM     per capita crime rate by town\n",
    " - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    " - INDUS    proportion of non-retail business acres per town\n",
    " - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    " - NOX      nitric oxides concentration (parts per 10 million)\n",
    " - RM       average number of rooms per dwelling\n",
    " - AGE      proportion of owner-occupied units built prior to 1940\n",
    " - DIS      weighted distances to five Boston employment centres\n",
    " - RAD      index of accessibility to radial highways\n",
    " - TAX      full-value property-tax rate per $10,000\n",
    " - PTRATIO  pupil-teacher ratio by town\n",
    " - LSTAT    % lower status of the population\n",
    " - Target:   Median value of owner-occupied homes in 1000s USD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf46f70",
   "metadata": {},
   "source": [
    "The following cell will create a Dataframe of the features of the Boston data as well as a target variable representing the variable we wish to predict (housing value). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22683961",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### Question 1\n",
    "\n",
    "Let's model this housing price data! Before we can do this, however, we need to split the data into training and test sets. Remember that the response vector (housing prices) lives in the `target` attribute. A random seed is set here so that we can deterministically generate the same splitting in the future if we want to test our result again and find potential bugs.\n",
    "\n",
    "Use the [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to split out 10% of the data for the test set. Call the resulting splits `X_train`, `X_holdout`, `Y_train`, `Y_holdout`. Here \"holdout\" refers to the fact that we're going to hold this data our when training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61341eb1",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(45)\n",
    "\n",
    "X = boston\n",
    "Y = target\n",
    "\n",
    "X_train, X_Holdout, Y_train, Y_holdout = train_test_split(X, Y, test_size = .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da30caf",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### Question 2.1\n",
    "\n",
    "As a warmup, fit a linear model to describe the relationship between the housing price and all available covariates. We've imported `sklearn.linear_model` as `lm`, so you can use that instead of typing out the whole module name. Fill in the cells below to \n",
    "\n",
    "1) fit a linear regression model to the covariates using the training data, then \n",
    "\n",
    "2) predict housing values using the holdout x values, and \n",
    "\n",
    "3) create a scatter plot for these predictions vs. the true prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28ac60-d02b-43b5-9bf4-bbb9a761d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931974c4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "linear_model = lm.LinearRegression()\n",
    "\n",
    "# Fit your linear model\n",
    "linear_model.fit(X_train,Y_train)\n",
    "\n",
    "# Predict housing prices on the test set\n",
    "Y_pred = linear_model.predict(X_Holdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3426d1-b27d-4c31-89d3-4d266a7b90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_pred, Y_holdout)\n",
    "plt.xlabel(\"predicted y_values\"); plt.ylabel(\"Actual Y-values\"); plt.title(\"Scatterplot of Predicted vs Actual Y-values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534440b0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-655458f2b7de0645",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### Question 2.2\n",
    "\n",
    "Briefly analyze the scatter plot above. Do you notice any outliers? Write your answer in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026693f3",
   "metadata": {},
   "source": [
    "**Your response**:  I wouldn't say that there are any distinct outliers considering we want things to be at the intersection between the axis ticks. For the most part everything increases one to one. Two \"outliers\" I guess would be at a predicted value of 10 and a 25 actual, while we also had a predicted value of 10 and had a 24 ish actual/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b6b96",
   "metadata": {},
   "source": [
    "Alternatively, we can plot the residuals vs. our model predictions. Ideally they'd all be zero. Given the inevitably of noise, we'd at least like them to be scatter randomly across the line where the residual is zero. These residuals appear to be pretty good, though it seems evident that our housing model is overpredicting housing prices at low and high real values. Note that this might vary a little bit depending on your random sample of training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_pred, Y_holdout - Y_pred, alpha=0.5)\n",
    "plt.ylabel(\"Residual $(y - \\hat{y})$\")\n",
    "plt.xlabel(\"Predicted Prices $(\\hat{y})$\")\n",
    "plt.title(\"Residuals vs Predicted Prices\")\n",
    "plt.title(\"Residual of prediction for i'th house\")\n",
    "plt.axhline(y = 0, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cad925",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### Question 3.1\n",
    "\n",
    "As we find from the scatter plot, our model is not perfect. If it were perfect, we would see the identity line (i.e. a line of slope 1). Compute the root mean squared error (RMSE) of the predicted responses: \n",
    "\n",
    "$$\n",
    "\\textbf{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n \\left( y_i - \\hat{y}_i \\right)^2 }\n",
    "$$\n",
    "\n",
    "Fill out the function below and compute the RMSE for our predictions on both the training data `X_train` and the held out set `X_holdout`.  Your implementation **should not** use for loops.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53690c8a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def rmse(actual_y, predicted_y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        predicted_y: an array of the prediction from the model\n",
    "        actual_y: an array of the groudtruth label\n",
    "        \n",
    "    Returns:\n",
    "        The root mean square error between the prediction and the groudtruth\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual_y-predicted_y)**2))\n",
    "\n",
    "\n",
    "train_error = rmse(Y_train, linear_model.predict(X_train))\n",
    "holdout_error = rmse(Y_holdout, linear_model.predict(X_Holdout))\n",
    "\n",
    "\n",
    "print(\"Training RMSE:\", train_error)\n",
    "print(\"Holdout RMSE:\", holdout_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d395e1c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0f349e0d791db2f2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### Question 3.2\n",
    "\n",
    "Is your training error lower than the error on the data the model never got to see? If so, why could this be happening? Answer in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c318a46",
   "metadata": {},
   "source": [
    "**Your response**: Our training error is lower than the error than on the data set that model never got to see. This could be because of overfitting on our X-set so we are actually predicting noise instead of a real model. This makes our predictons on the holdouts to be larger than the training error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5f143e",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840182d",
   "metadata": {},
   "source": [
    "Sometimes we can get even lower loss by adding more features. For example, the code below adds the square, square root, and hyperbolic tangent of every feature to the design matrix. We've chosen these bizarre features specifically to highlight overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_with_extra_features = boston.copy()\n",
    "for feature_name in boston.columns:\n",
    "    boston_with_extra_features[feature_name + \"^2\"] = boston_with_extra_features[feature_name] ** 2\n",
    "    boston_with_extra_features[\"sqrt\" + feature_name] = np.sqrt(boston_with_extra_features[feature_name])\n",
    "    boston_with_extra_features[\"tanh\" + feature_name] = np.tanh(boston_with_extra_features[feature_name])  \n",
    "\n",
    "boston_with_extra_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c40bd6",
   "metadata": {},
   "source": [
    "We split up our data again and refit the model. From this cell forward, we append `2` to the variable names `X_train, X_holdout, Y_train, Y_holdout, train_error, holdout_error` in order to maintain our original data. **Make sure you use these variable names from this cell forward**, at least until we get to the part where we create version 3 of each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468980f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "X = boston_with_extra_features\n",
    "X_train2, X_holdout2, Y_train2, Y_holdout2 = train_test_split(X, Y, test_size = 0.10)\n",
    "linear_model.fit(X_train2, Y_train2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2268d",
   "metadata": {},
   "source": [
    "Looking at our training and test RMSE, we see that they are lower than you computed earlier. This strange model is seemingly better, even though it includes seemingly useless features like the hyperbolic tangent of the average number of rooms per dwelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06172b4e-3376-48da-a3eb-7eb3cad1aa87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_error2 = rmse(Y_train2, linear_model.predict(X_train2)) \n",
    "holdout_error2 = rmse(Y_holdout2, linear_model.predict(X_holdout2))\n",
    "\n",
    "print(\"Training RMSE:\", train_error2)\n",
    "print(\"Holdout RMSE:\", holdout_error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143913b5",
   "metadata": {},
   "source": [
    "The code below generates the training and holdout RMSE for 49 different models stores the results in a DataFrame. The first model uses only the first feature \"CRIM\". The second model uses the first two features \"CRIM\" and \"ZN\", and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_vs_N = pd.DataFrame(columns = [\"N\", \"Training Error\", \"Holdout Error\"])\n",
    "range_of_num_features = range(1, X_train2.shape[1] + 1)\n",
    "\n",
    "for N in range_of_num_features:\n",
    "    X_train_first_N_features = X_train2.iloc[:, :N]    \n",
    "    \n",
    "    linear_model.fit(X_train_first_N_features, Y_train2)\n",
    "    train_error_overfit = rmse(Y_train2, linear_model.predict(X_train_first_N_features))\n",
    "    \n",
    "    X_holdout_first_N_features = X_holdout2.iloc[:, :N]\n",
    "    holdout_error_overfit = rmse(Y_holdout2, linear_model.predict(X_holdout_first_N_features))    \n",
    "    errors_vs_N.loc[len(errors_vs_N)] = [N, train_error_overfit, holdout_error_overfit]\n",
    "    \n",
    "errors_vs_N.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c6f81",
   "metadata": {},
   "source": [
    "If we plot the training and holdout error as we add each additional feature, our training error gets lower and lower, and in fact it's possible to prove with linear algebra that the training error will decrease monotonically.\n",
    "\n",
    "By contrast, the error on unseen held out data is higher for the models with more parameters, since the lessons learned from these last 20+ features aren't actually useful when applied to unseen data. That is, these models aren't generalizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a559f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = errors_vs_N[\"N\"], y = errors_vs_N[\"Training Error\"], label = \"Training Error\")\n",
    "sns.lineplot(x = errors_vs_N[\"N\"], y = errors_vs_N[\"Holdout Error\"], label = \"Holdout Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b663e8fa",
   "metadata": {},
   "source": [
    "This plot is a useful tool for **model selection**: the best model is the one the lowest error on the holdout set, i.e. the one that includes parameters 1 through 28."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2bed37",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2756454b",
   "metadata": {},
   "source": [
    "As an alternative example, instead of using only the first N features, we can use various different regularization strengths. For example, for really low regularization strengths (e.g. $\\alpha = 10^{-12}$), we get a model that is nearly identical to our linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "regularized_model = Ridge(alpha = 1e-12)\n",
    "regularized_model.fit(X_train2, Y_train2)\n",
    "ridge_coefs_low_regularization = regularized_model.coef_\n",
    "\n",
    "linear_model = linear_model.fit(X_train2, Y_train2)\n",
    "linear_coefs = linear_model.coef_\n",
    "\n",
    "# what is the difference between the Ridge and OLS coefficients?\n",
    "(ridge_coefs_low_regularization - linear_coefs).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5106d21",
   "metadata": {},
   "source": [
    "However, if we pick a large regularization strength, e.g. $\\alpha = 10^4$, we see that the resulting parameters are much smaller in magnitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6915c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularized_model = Ridge(alpha = 10**4)\n",
    "regularized_model.fit(X_train2, Y_train2)\n",
    "regularized_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71babab6-6166-456f-8df8-022a09a3f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb6c42",
   "metadata": {},
   "source": [
    "### Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b081b0",
   "metadata": {},
   "source": [
    "In order to properly regularize a model, the features should be at the same scale. Otherwise the model has to spend more of its parameter budget to use \"small\" features (e.g. lengths in inches) compared to \"large\" features (e.g. lengths in kilometers).\n",
    "\n",
    "To do this we can use a Standard Scaler to create a new version of the DataFrame where every column has zero mean and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61582b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(boston_with_extra_features)\n",
    "boston_with_extra_features_scaled = pd.DataFrame(ss.transform(boston_with_extra_features), columns = boston_with_extra_features.columns)\n",
    "boston_with_extra_features_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07ca2c",
   "metadata": {},
   "source": [
    "Let's now regenerate the training and holdout sets using this new rescaled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38198058",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "X = boston_with_extra_features_scaled\n",
    "X_train3, X_holdout3, Y_train3, Y_holdout3 = train_test_split(X, Y, test_size = 0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833468f4",
   "metadata": {},
   "source": [
    "Fitting our regularized model with $\\alpha = 10^2$ on this scaled data, we now see that our coefficients are of about the same magnitude. This is because all of our features are of around the same magnitude, whereas in the unscaled data, some of the features like TAX^2 were much larger than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf50325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "regularized_model = Ridge(alpha = 10**2)\n",
    "regularized_model.fit(X_train3, Y_train3)\n",
    "regularized_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9184d0",
   "metadata": {},
   "source": [
    "### Finding an Optimum Alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae4711",
   "metadata": {},
   "source": [
    "In the cell below, write code that generates a DataFrame with the training and holdout error for the range of alphas given. Make sure you're using the 3rd training and holdout sets, which have been rescaled!\n",
    "\n",
    "**Note: You should use all features for every single model that you fit, i.e. you're not going to be keeping only the first N features.**\n",
    "\n",
    "*Hint*: It is possible to \"append\" or add a row to a DataFrame by calling `loc`, e.g. `df.loc[len(df)] = [2, 3, 4]` (assuming `df` has 3 columns!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "error_vs_alpha = pd.DataFrame(columns = [\"alpha\", \"Training Error\", \"Holdout Error\"])\n",
    "range_of_alphas = 10**np.linspace(-5, 4, 40)\n",
    "\n",
    "for alpha in range_of_alphas:\n",
    "    regularized_model = Ridge(alpha= alpha)\n",
    "    regularized_model.fit(X_train3, Y_train3)\n",
    "\n",
    "    train_error_overfit = rmse(Y_train3, regularized_model.predict(X_train3))\n",
    "    holdout_error_overfit = rmse(Y_holdout3, regularized_model.predict(X_holdout3))\n",
    "    \n",
    "    error_vs_alpha.loc[len(error_vs_alpha)] = [alpha, train_error_overfit, holdout_error_overfit]\n",
    "\n",
    "error_vs_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b677a82e",
   "metadata": {},
   "source": [
    "Below we plot your training and holdout set error for the range of alphas given. You should see a figure where training error goes down as model complexity increases, but the error on the held out set is large for extreme values of alpha, and minimized for some intermediate value.\n",
    "\n",
    "Note that on your plot, the **x-axis is in the inverse of complexity**! In other words, small alpha models (on the left) are complex, because there is no regularization. That's why the training error is lowest on the left side of the plot, as this is where overfitting occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ba9f95-b3ad-413a-a29e-a86157a35e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = error_vs_alpha[\"alpha\"], y = error_vs_alpha[\"Training Error\"], label = \"Training Error\")\n",
    "sns.lineplot(x = error_vs_alpha[\"alpha\"], y = error_vs_alpha[\"Holdout Error\"], label = \"Holdout Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313b465",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7b0a9",
   "metadata": {},
   "source": [
    "From the plot above, what is the best alpha to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e3ca8",
   "metadata": {},
   "source": [
    "**Your response**: From the plot above it seems pretty clear that we want to use a pretty low alpha where there's a dip in the graph close to 0. In this case (after looking at the table), the best alpha for this is around .41. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8035b5d",
   "metadata": {},
   "source": [
    "## Test Set vs. Validation Set (a.k.a. Development Set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b1ce15",
   "metadata": {},
   "source": [
    "In the plots above, we trained our models on a training set, and plotted the resulting RMSE on the training set in blue. We also held out a set of data, and plotted the error on this holdout set in red, calling it the \"holdout set error\". \n",
    "\n",
    "For the example above, since we used the holdout set to pick a hyperparameter, we'd call the holdout set a \"validation set\" or \"development set\". These terms are exactly synonomous.\n",
    "\n",
    "It would not be accurate to call this line the \"test set error\", because we did not use this dataset as a test set. While it is true that your code never supplied X_test3 or Y_test3 to the fit function of the ridge regression models, once you decide to use the holdout set to select between different models, different hyperparameters, or different sets of features, then we are not using that dataset as a \"test set\".\n",
    "\n",
    "That is, since we've used this holdout set for picking alpha, the resulting errors are no longer unbiased predictors of our performance on unseen models -- the true error on an unseen dataset is likely to be somewhat higher than the validation set. After all, we trained 40 models and picked the best one!\n",
    "\n",
    "In many real world contexts, model builders will split their data into three sets: training, validation, and test sets, where the test set is only ever used once. That is, there are two holdout sets: One used as a development set (for model selection), and one used a test set (for providing an unbiased estimate of error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a8d94",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cv",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## An Alternate Strategy for Hyper Parameter Selection: K-Fold Cross Validation\n",
    "\n",
    "Earlier we used the holdout method for model selection (the holdout method is also sometimes called \"simple cross validation\"). Another approach is K-fold cross validation. This allows us to use more data for training instead of having to set aside some specifically for hyperparameter selection. However, doing so requires more computation resources as we'll have to fit K models per hyperparameter choice.\n",
    "\n",
    "In this class, there's really no reason not to use cross validation. However, in environments where models are very expensive to train (e.g. deep learning), you'll typically prefer using a holdout set (simple cross validation) rather than K-fold cross validation.\n",
    "\n",
    "To emphasize what K-fold cross validation actually means, we're going to manually carry out the procedure. Recall the approach looks something like the figure below for 5-fold cross validation:\n",
    "\n",
    "<img src=\"grid_search_cross_validation.png\" width=500px>\n",
    "\n",
    "When we use K-fold cross validation, rather than using a held out set for model selection, we instead use the training set for model selection. To select between various features, various models, or various hyperparameters, we split the training set further into multiple temporary train and validation sets (each split is called a \"fold\", hence k-fold cross validation). We will use the average validation error across all k folds to make our optimal feature, model, and hyperparameter choices. In this example, we'll only use this procedure for hyperparameter selection, specifically to choose the best alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9da2288",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### Question 5\n",
    "\n",
    "Scikit-learn has built-in support for cross validation.  However, to better understand how cross validation works complete the following function which cross validates a given model. Use X_train3 and Y_train3.\n",
    "\n",
    "1. Use the [`KFold.split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function to get 4 splits on the training data. Note that `split` returns the row indices of the data for that split.\n",
    "2. For **each** split:\n",
    "    1. Select out the training and validation rows based on the split indices and features.\n",
    "    2. Compute the RMSE on the validation split.\n",
    "    3. Return the average error across all cross validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea349e-ffdf-4cea-bc93-ae56eec8585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a9958",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def compute_CV_error(model, X_train, Y_train):\n",
    "    '''\n",
    "    Split the training data into 4 subsets.\n",
    "    For each subset, \n",
    "        fit a model holding out that subset\n",
    "        compute the MSE on that subset (the validation set)\n",
    "    You should be fitting 4 models total.\n",
    "    Return the average MSE of these 4 folds.\n",
    "\n",
    "    Args:\n",
    "        model: an sklearn model with fit and predict functions \n",
    "        X_train (data_frame): Training data\n",
    "        Y_train (data_frame): Label \n",
    "\n",
    "    Return:\n",
    "        the average validation MSE for the 4 splits.\n",
    "    '''\n",
    "    kf = KFold(n_splits=4)\n",
    "    validation_errors = np.empty(0)\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # split the data\n",
    "        split_X_train, split_X_valid = X_train.iloc[train_idx,:], X_train.iloc[valid_idx,:]\n",
    "        split_Y_train, split_Y_valid = Y_train[train_idx], Y_train[valid_idx]\n",
    "\n",
    "        # Fit the model on the training spli\n",
    "        model.fit(split_X_train, split_Y_train)\n",
    "\n",
    "        # Predict housing prices on the test set\n",
    "        y_pred = model.predict(split_X_valid)\n",
    "        \n",
    "        # Compute the RMSE on the validation split\n",
    "        R_mse = rmse(split_Y_valid, y_pred)\n",
    "\n",
    "        validation_errors = np.append(validation_errors, R_mse)\n",
    "        \n",
    "    return np.mean(validation_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea02fd8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Use `compute_CV_error` to add a new column to `error_vs_alpha` which gives the 4-fold cross validation error for the given choice of alpha.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb107b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_errors = np.empty(0)\n",
    "range_of_alphas = 10**np.linspace(-5, 4, 40)\n",
    "\n",
    "for alpha in range_of_alphas:\n",
    "    \n",
    "    cv_errors = np.append(cv_errors,compute_CV_error(Ridge(alpha= alpha), X_train3, Y_train3))\n",
    "    \n",
    "error_vs_alpha[\"CV Error\"] = cv_errors\n",
    "error_vs_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7acdc",
   "metadata": {},
   "source": [
    "The code below shows the holdout error that we computed in the previous problem as well as the 4-fold cross validation error. Note that the cross validation error shows a similar dependency on alpha relative to the holdout error. This is because they are both doing the same thing, namely trying to estimate the expected error on unseen data drawn from distribution from which the training set was drawn. \n",
    "\n",
    "In other words, this figure compares the holdout method with 4-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba60747-bd5c-49fb-8a7d-98b9334ac966",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = np.log(error_vs_alpha[\"alpha\"]), y = error_vs_alpha[\"Holdout Error\"], label = \"Holdout Error\")\n",
    "sns.lineplot(x = np.log(error_vs_alpha[\"alpha\"]), y = error_vs_alpha[\"CV Error\"], label = \"CV Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8c8f1",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Submission\n",
    "\n",
    "Congratulations! You are finished with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a984a1e",
   "metadata": {},
   "source": [
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71550b",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order. Then execute the following commands in the File menu:\n",
    "\n",
    "* Save and Checkpoint\n",
    "* Close and Halt\n",
    "\n",
    "Then submit your notebook for Canvas Assignment Lab7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3b649",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
